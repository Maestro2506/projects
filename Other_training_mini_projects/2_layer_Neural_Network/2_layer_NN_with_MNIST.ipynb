{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "2-NN-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJiYfWWbcS8f"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist.loader import MNIST\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-4czdqcS8g"
      },
      "source": [
        "in_dim = 785\n",
        "hidden_dim = 100\n",
        "out_dim = 10\n",
        "eta = 0.1  # Learning rate. You might try different rates (e.g. 0.001, 0.01, 0.1) to maximize the accuracy\n",
        "\n",
        "# matrix to store the activation h1...hk \n",
        "hl_input = np.zeros((1, hidden_dim + 1))\n",
        "hl_input[0, 0] = 1\n",
        "\n",
        "def weight_update(feature, label, weight_i2h, weight_h2o):\n",
        "    scores_hl = np.dot(feature.reshape(1, in_dim), weight_i2h)\n",
        "    sig_hl = expit(scores_hl)\n",
        "    hl_input[0, 1:] = sig_hl\n",
        "\n",
        "    scores_ol = np.dot(hl_input, weight_h2o)\n",
        "    sig_ol = expit(scores_ol)\n",
        "\n",
        "    y_i = np.zeros((1,out_dim))\n",
        "    y_i[0,label] = 1\n",
        "    delta_ol = sig_ol*(1-sig_ol)*(sig_ol-y_i)\n",
        "    weight_h2o -= eta*np.dot(hl_input.T,delta_ol)\n",
        "\n",
        "    delta_hl = sig_hl*(1-sig_hl)*np.dot(delta_ol,weight_h2o[1:].T)\n",
        "    weight_i2h-= eta*np.dot(feature.reshape(in_dim,1),delta_hl)\n",
        "\n",
        "    return weight_i2h, weight_h2o\n",
        "\n",
        "\n",
        "def get_predictions(dataset, weight_i2h, weight_h2o):\n",
        "    hl_in = np.zeros((dataset.shape[0], hidden_dim + 1))\n",
        "    hl_in[:, 0] = 1\n",
        "    scores_hl = np.dot(dataset, weight_i2h)\n",
        "    sig_hl = expit(scores_hl)\n",
        "    hl_in[:,1:] = sig_hl\n",
        "    scores_ol = np.dot(hl_in, weight_h2o)\n",
        "    sig_ol = expit(scores_ol)\n",
        "    labels = np.argmax(sig_ol, axis=1)\n",
        "    \n",
        "    return labels\n",
        "\n",
        "\n",
        "def train(train_set, labels, weight_i2h, weight_h2o):\n",
        "    for i in range(0, train_set.shape[0]):\n",
        "        weight_i2h, weight_h2o = weight_update(train_set[i, :], labels[i], weight_i2h, weight_h2o)\n",
        "    return weight_i2h, weight_h2o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o7ckUQdcS8g"
      },
      "source": [
        "## Evaluating NN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J70yiXGXcS8h"
      },
      "source": [
        "mndata = MNIST('./data')\n",
        "X_train, Y_train = map(np.array, mndata.load_training())\n",
        "X_test, Y_test = map(np.array, mndata.load_testing())\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train = np.hstack((np.ones((X_train.shape[0],1)),X_train)) \n",
        "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7q-R6gucS8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c69af4d-60de-49bc-e749-47795ecc7098"
      },
      "source": [
        "num_epochs = 5\n",
        "\n",
        "weight_1 = np.random.uniform(-0.05,0.05,(in_dim,hidden_dim))\n",
        "weight_2 = np.random.uniform(-0.05,0.05,(hidden_dim+1,out_dim))\n",
        "\n",
        "arr_train_acc = []\n",
        "arr_test_acc = [] \n",
        "\n",
        "for i in range(1, num_epochs+1):\n",
        "    # Test network on training set and get training accuracy\n",
        "    pred_train_labels = get_predictions(X_train, weight_1, weight_2)  \n",
        "    curr_accu = accuracy_score(Y_train, pred_train_labels)\n",
        "\n",
        "    print(\"Epoch \" + str(i) + \" :\\tTraining Set Accuracy = \" + str(curr_accu))\n",
        "    # Test network on test set and get accuracy on test set\n",
        "    pred_test_labels = get_predictions(X_test, weight_1, weight_2)  \n",
        "    test_accu = accuracy_score(Y_test, pred_test_labels)\n",
        "    print(\"\\t\\tTest Set Accuracy = \" + str(test_accu))\n",
        "    # Train the network\n",
        "    weight_1, weight_2 = train(X_train, Y_train, weight_1, weight_2)    \n",
        "\n",
        "    arr_train_acc.append(curr_accu)\n",
        "    arr_test_acc.append(test_accu)\n",
        "\n",
        "# Test network on test set and get test accuracy\n",
        "pred_test_labels = get_predictions(X_test, weight_1, weight_2)  \n",
        "test_accu = accuracy_score(Y_test, pred_test_labels)\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\t\\tFinal Accuracy = \" + str(test_accu) + \"\\n\\nConfusion Matrix :\\n\")\n",
        "print(confusion_matrix(Y_test, pred_test_labels))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 :\tTraining Set Accuracy = 0.10515\n",
            "\t\tTest Set Accuracy = 0.1035\n",
            "Epoch 2 :\tTraining Set Accuracy = 0.929\n",
            "\t\tTest Set Accuracy = 0.9316\n",
            "Epoch 3 :\tTraining Set Accuracy = 0.9537833333333333\n",
            "\t\tTest Set Accuracy = 0.9525\n",
            "Epoch 4 :\tTraining Set Accuracy = 0.96395\n",
            "\t\tTest Set Accuracy = 0.9602\n",
            "Epoch 5 :\tTraining Set Accuracy = 0.97065\n",
            "\t\tTest Set Accuracy = 0.9635\n",
            "\t\tFinal Accuracy = 0.9676\n",
            "\n",
            "Confusion Matrix :\n",
            "\n",
            "[[ 972    0    0    1    0    2    2    1    1    1]\n",
            " [   0 1123    2    2    0    1    2    1    4    0]\n",
            " [   8    2  996    7    5    0    2    7    5    0]\n",
            " [   0    0    5  994    0    2    0    5    3    1]\n",
            " [   1    0    4    0  950    0    6    1    2   18]\n",
            " [   7    3    2   13    2  841   10    3    5    6]\n",
            " [  10    4    1    1    3    4  930    0    5    0]\n",
            " [   3   11   15    6    1    0    1  975    0   16]\n",
            " [   4    3    3    7    5    4    5    4  935    4]\n",
            " [   6    6    0   13    9    2    0    7    6  960]]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}