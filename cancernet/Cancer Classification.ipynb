{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content/drive/My Drive/DeepLearn/datasets/idc\\training\n",
      "Found 255815 images belonging to 2 classes.\n",
      "Found 42660 images belonging to 2 classes.\n",
      "Found 99906 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "1998/1998 [==============================] - 453s 227ms/step - loss: 0.7428 - accuracy: 0.7843 - val_loss: 0.4302 - val_accuracy: 0.8131\n",
      "Epoch 2/40\n",
      "1998/1998 [==============================] - 441s 221ms/step - loss: 0.6374 - accuracy: 0.8084 - val_loss: 0.4457 - val_accuracy: 0.8107\n",
      "Epoch 3/40\n",
      "1998/1998 [==============================] - 480s 240ms/step - loss: 0.6098 - accuracy: 0.8164 - val_loss: 0.4402 - val_accuracy: 0.8091\n",
      "Epoch 4/40\n",
      "1998/1998 [==============================] - 448s 224ms/step - loss: 0.5902 - accuracy: 0.8234 - val_loss: 0.4312 - val_accuracy: 0.8155\n",
      "Epoch 5/40\n",
      "1998/1998 [==============================] - 524s 262ms/step - loss: 0.5823 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.8243\n",
      "Epoch 6/40\n",
      "1998/1998 [==============================] - 460s 230ms/step - loss: 0.5721 - accuracy: 0.8290 - val_loss: 0.4369 - val_accuracy: 0.8183\n",
      "Epoch 7/40\n",
      "1998/1998 [==============================] - 435s 218ms/step - loss: 0.5661 - accuracy: 0.8300 - val_loss: 0.4306 - val_accuracy: 0.8232\n",
      "Epoch 8/40\n",
      "1998/1998 [==============================] - 444s 222ms/step - loss: 0.5600 - accuracy: 0.8314 - val_loss: 0.4319 - val_accuracy: 0.8254\n",
      "Epoch 9/40\n",
      "1998/1998 [==============================] - 444s 222ms/step - loss: 0.5569 - accuracy: 0.8333 - val_loss: 0.4219 - val_accuracy: 0.8311\n",
      "Epoch 10/40\n",
      "1998/1998 [==============================] - 437s 219ms/step - loss: 0.5540 - accuracy: 0.8339 - val_loss: 0.4385 - val_accuracy: 0.8273\n",
      "Epoch 11/40\n",
      "1998/1998 [==============================] - 415s 208ms/step - loss: 0.5504 - accuracy: 0.8350 - val_loss: 0.4290 - val_accuracy: 0.8296\n",
      "Epoch 12/40\n",
      "1998/1998 [==============================] - 418s 209ms/step - loss: 0.5481 - accuracy: 0.8357 - val_loss: 0.4383 - val_accuracy: 0.8274\n",
      "Epoch 13/40\n",
      "1998/1998 [==============================] - 421s 211ms/step - loss: 0.5446 - accuracy: 0.8363 - val_loss: 0.4318 - val_accuracy: 0.8250\n",
      "Epoch 14/40\n",
      "1998/1998 [==============================] - 418s 209ms/step - loss: 0.5427 - accuracy: 0.8368 - val_loss: 0.4370 - val_accuracy: 0.8266\n",
      "Epoch 15/40\n",
      "1998/1998 [==============================] - 415s 208ms/step - loss: 0.5427 - accuracy: 0.8372 - val_loss: 0.4360 - val_accuracy: 0.8285\n",
      "Epoch 16/40\n",
      "1998/1998 [==============================] - 409s 204ms/step - loss: 0.5398 - accuracy: 0.8390 - val_loss: 0.4405 - val_accuracy: 0.8275\n",
      "Epoch 17/40\n",
      "1998/1998 [==============================] - 434s 217ms/step - loss: 0.5387 - accuracy: 0.8384 - val_loss: 0.4336 - val_accuracy: 0.8265\n",
      "Epoch 18/40\n",
      "1998/1998 [==============================] - 417s 209ms/step - loss: 0.5366 - accuracy: 0.8398 - val_loss: 0.4324 - val_accuracy: 0.8284\n",
      "Epoch 19/40\n",
      "1998/1998 [==============================] - 412s 206ms/step - loss: 0.5347 - accuracy: 0.8397 - val_loss: 0.4354 - val_accuracy: 0.8270\n",
      "Epoch 20/40\n",
      "1998/1998 [==============================] - 412s 206ms/step - loss: 0.5332 - accuracy: 0.8408 - val_loss: 0.4287 - val_accuracy: 0.8310\n",
      "Epoch 21/40\n",
      "1998/1998 [==============================] - 415s 208ms/step - loss: 0.5327 - accuracy: 0.8409 - val_loss: 0.4364 - val_accuracy: 0.8276\n",
      "Epoch 22/40\n",
      "1998/1998 [==============================] - 426s 213ms/step - loss: 0.5321 - accuracy: 0.8413 - val_loss: 0.4323 - val_accuracy: 0.8267\n",
      "Epoch 23/40\n",
      "1998/1998 [==============================] - 435s 218ms/step - loss: 0.5302 - accuracy: 0.8413 - val_loss: 0.4344 - val_accuracy: 0.8285\n",
      "Epoch 24/40\n",
      "1998/1998 [==============================] - 426s 213ms/step - loss: 0.5296 - accuracy: 0.8417 - val_loss: 0.4295 - val_accuracy: 0.8307\n",
      "Epoch 25/40\n",
      "1998/1998 [==============================] - 445s 223ms/step - loss: 0.5297 - accuracy: 0.8418 - val_loss: 0.4279 - val_accuracy: 0.8302\n",
      "Epoch 26/40\n",
      "1998/1998 [==============================] - 437s 219ms/step - loss: 0.5281 - accuracy: 0.8421 - val_loss: 0.4271 - val_accuracy: 0.8321\n",
      "Epoch 27/40\n",
      "1998/1998 [==============================] - 470s 235ms/step - loss: 0.5284 - accuracy: 0.8424 - val_loss: 0.4354 - val_accuracy: 0.8281\n",
      "Epoch 28/40\n",
      "1998/1998 [==============================] - 423s 212ms/step - loss: 0.5279 - accuracy: 0.8413 - val_loss: 0.4330 - val_accuracy: 0.8292\n",
      "Epoch 29/40\n",
      "1998/1998 [==============================] - 434s 217ms/step - loss: 0.5261 - accuracy: 0.8416 - val_loss: 0.4328 - val_accuracy: 0.8286\n",
      "Epoch 30/40\n",
      "1998/1998 [==============================] - 429s 215ms/step - loss: 0.5252 - accuracy: 0.8430 - val_loss: 0.4351 - val_accuracy: 0.8280\n",
      "Epoch 31/40\n",
      "1998/1998 [==============================] - 433s 217ms/step - loss: 0.5256 - accuracy: 0.8432 - val_loss: 0.4359 - val_accuracy: 0.8273\n",
      "Epoch 32/40\n",
      "1998/1998 [==============================] - 436s 218ms/step - loss: 0.5240 - accuracy: 0.8430 - val_loss: 0.4372 - val_accuracy: 0.8266\n",
      "Epoch 33/40\n",
      "1998/1998 [==============================] - 433s 217ms/step - loss: 0.5238 - accuracy: 0.8436 - val_loss: 0.4308 - val_accuracy: 0.8292\n",
      "Epoch 34/40\n",
      "1998/1998 [==============================] - 434s 217ms/step - loss: 0.5228 - accuracy: 0.8433 - val_loss: 0.4325 - val_accuracy: 0.8286\n",
      "Epoch 35/40\n",
      "1998/1998 [==============================] - 405s 203ms/step - loss: 0.5232 - accuracy: 0.8440 - val_loss: 0.4313 - val_accuracy: 0.8295\n",
      "Epoch 36/40\n",
      "1998/1998 [==============================] - 405s 203ms/step - loss: 0.5214 - accuracy: 0.8439 - val_loss: 0.4320 - val_accuracy: 0.8281\n",
      "Epoch 37/40\n",
      "1998/1998 [==============================] - 405s 203ms/step - loss: 0.5223 - accuracy: 0.8436 - val_loss: 0.4333 - val_accuracy: 0.8286\n",
      "Epoch 38/40\n",
      "1998/1998 [==============================] - 408s 204ms/step - loss: 0.5219 - accuracy: 0.8441 - val_loss: 0.4383 - val_accuracy: 0.8266\n",
      "Epoch 39/40\n",
      "1998/1998 [==============================] - 412s 206ms/step - loss: 0.5217 - accuracy: 0.8436 - val_loss: 0.4350 - val_accuracy: 0.8255\n",
      "Epoch 40/40\n",
      "1998/1998 [==============================] - 591s 296ms/step - loss: 0.5209 - accuracy: 0.8443 - val_loss: 0.4331 - val_accuracy: 0.8292\n",
      "Passed:  17449.98853778839\n",
      "Now evaluating the model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87     71451\n",
      "           1       0.65      0.88      0.75     28455\n",
      "\n",
      "    accuracy                           0.83     99906\n",
      "   macro avg       0.80      0.84      0.81     99906\n",
      "weighted avg       0.86      0.83      0.84     99906\n",
      "\n",
      "[[57690 13761]\n",
      " [ 3351 25104]]\n",
      "Accuracy: 0.8287189958561048\n",
      "Specificity: 0.8822351080653663\n",
      "Sensitivity: 0.8074064743670487\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from cancernet.cancernet2 import CancerNet\n",
    "from cancernet import config\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "NUM_EPOCHS=40; INIT_LR=1e-3; BS=128\n",
    "\n",
    "#lenTrain: 255815\n",
    "#lenVal: 42660\n",
    "#lenTest: 99906\n",
    "\n",
    "print(config.TRAIN_PATH)\n",
    "\n",
    "trainPaths=list(paths.list_images(config.TRAIN_PATH))\n",
    "lenTrain=len(trainPaths)\n",
    "valPaths=list(paths.list_images(config.VAL_PATH))\n",
    "lenVal=len(valPaths)\n",
    "testPaths=list(paths.list_images(config.TEST_PATH))\n",
    "lenTest=len(testPaths)\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=np_utils.to_categorical(trainLabels)\n",
    "classTotals=trainLabels.sum(axis=0)\n",
    "classWeight=classTotals.max()/classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1/255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "#LOAD MODEL\n",
    "#model = load_model('model.h5')\n",
    "\n",
    "model=CancerNet.build(width=48,height=48,depth=3,classes=2)\n",
    "#model = load_model('model.h5')\n",
    "\n",
    "opt=Adagrad(lr=INIT_LR,decay=INIT_LR/NUM_EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "classWeight = {i : classWeight[i] for i in range(2)}\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "M=model.fit(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=lenTrain//BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=lenVal//BS,\n",
    "\tclass_weight=classWeight,\n",
    "\tepochs=NUM_EPOCHS)\n",
    "print(\"Passed: \", time.time()-start)\n",
    "\n",
    "#SAVE MODEL\n",
    "model.save('model-AlexNet.h5')\n",
    "\n",
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices=model.predict(testGen,steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm=confusion_matrix(testGen.classes,pred_indices)\n",
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N = 40\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N), M.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0,N), M.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255815 images belonging to 2 classes.\n",
      "Found 42660 images belonging to 2 classes.\n",
      "Found 99906 images belonging to 2 classes.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87     71451\n",
      "           1       0.65      0.88      0.75     28455\n",
      "\n",
      "    accuracy                           0.83     99906\n",
      "   macro avg       0.80      0.84      0.81     99906\n",
      "weighted avg       0.86      0.83      0.84     99906\n",
      "\n",
      "[[57690 13761]\n",
      " [ 3351 25104]]\n",
      "Accuracy: 0.8287189958561048\n",
      "Specificity: 0.8822351080653663\n",
      "Sensitivity: 0.8074064743670487\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from cancernet.cancernet2 import CancerNet\n",
    "from cancernet import config\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "\n",
    "BS=128\n",
    "\n",
    "trainPaths=list(paths.list_images(config.TRAIN_PATH))\n",
    "lenTrain=len(trainPaths)\n",
    "valPaths=list(paths.list_images(config.VAL_PATH))\n",
    "lenVal=len(valPaths)\n",
    "testPaths=list(paths.list_images(config.TEST_PATH))\n",
    "lenTest=len(testPaths)\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=np_utils.to_categorical(trainLabels)\n",
    "classTotals=trainLabels.sum(axis=0)\n",
    "classWeight=classTotals.max()/classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1/255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "\n",
    "model=CancerNet.build(width=48,height=48,depth=3,classes=2)\n",
    "model = load_model('model-AlexNet.h5')\n",
    "\n",
    "classWeight = {i : classWeight[i] for i in range(2)}\n",
    "\n",
    "pred_indices=model.predict(testGen,steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm=confusion_matrix(testGen.classes,pred_indices)\n",
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (48, 48, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "image1 = load('0.png')\n",
    "image2 = load('1.png')\n",
    "print(np.argmax(model.predict(image1),axis=1))\n",
    "print(np.argmax(model.predict(image2),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
